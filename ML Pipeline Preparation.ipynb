{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    X = 1\n",
    "    B = 2\n",
    "    return X, B\n",
    "\n",
    "test2 = test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(['punkt','wordnet'])\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import inspect\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct      1.0   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct      1.0   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct      1.0   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct      1.0   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct      1.0   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0      0.0    0.0          0.0           0.0               0.0      ...         \n",
       "1      0.0    0.0          1.0           0.0               0.0      ...         \n",
       "2      0.0    0.0          0.0           0.0               0.0      ...         \n",
       "3      1.0    0.0          1.0           0.0               1.0      ...         \n",
       "4      0.0    0.0          0.0           0.0               0.0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "1          0.0                   0.0              1.0     0.0    1.0   0.0   \n",
       "2          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "3          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "4          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0         0.0   0.0            0.0            0.0  \n",
       "1         0.0   0.0            0.0            0.0  \n",
       "2         0.0   0.0            0.0            0.0  \n",
       "3         0.0   0.0            0.0            0.0  \n",
       "4         0.0   0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///TH_DBEngine614.db')\n",
    "df = pd.read_sql_table('df_small', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>direct</th>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>...</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "      <td>10634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>...</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "      <td>13036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>...</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "genre                                                                          \n",
       "direct    10634    10634  10634        10634         10634             10634   \n",
       "news      13036    13036  13036        13036         13036             13036   \n",
       "social     2358     2358   2358         2358          2358              2358   \n",
       "\n",
       "        search_and_rescue  security  military  child_alone      ...        \\\n",
       "genre                                                           ...         \n",
       "direct              10634     10634     10634        10634      ...         \n",
       "news                13036     13036     13036        13036      ...         \n",
       "social               2358      2358      2358         2358      ...         \n",
       "\n",
       "        aid_centers  other_infrastructure  weather_related  floods  storm  \\\n",
       "genre                                                                       \n",
       "direct        10634                 10634            10634   10634  10634   \n",
       "news          13036                 13036            13036   13036  13036   \n",
       "social         2358                  2358             2358    2358   2358   \n",
       "\n",
       "         fire  earthquake   cold  other_weather  direct_report  \n",
       "genre                                                           \n",
       "direct  10634       10634  10634          10634          10634  \n",
       "news    13036       13036  13036          13036          13036  \n",
       "social   2358        2358   2358           2358           2358  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts = df.drop(['id','message','original'], axis=1).groupby('genre').count()\n",
    "# test = genre_counts.sum()/genre_counts.count()\n",
    "# test_titles = list(test.index)\n",
    "# test_titles\n",
    "# genre_counts\n",
    "list(genre_counts.loc['direct'])\n",
    "genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.related.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.message.values\n",
    "Y = df.drop(['message','id','original','genre','child_alone'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related',\n",
       " 'request',\n",
       " 'offer',\n",
       " 'aid_related',\n",
       " 'medical_help',\n",
       " 'medical_products',\n",
       " 'search_and_rescue',\n",
       " 'security',\n",
       " 'military',\n",
       " 'water',\n",
       " 'food',\n",
       " 'shelter',\n",
       " 'clothing',\n",
       " 'money',\n",
       " 'missing_people',\n",
       " 'refugees',\n",
       " 'death',\n",
       " 'other_aid',\n",
       " 'infrastructure_related',\n",
       " 'transport',\n",
       " 'buildings',\n",
       " 'electricity',\n",
       " 'tools',\n",
       " 'hospitals',\n",
       " 'shops',\n",
       " 'aid_centers',\n",
       " 'other_infrastructure',\n",
       " 'weather_related',\n",
       " 'floods',\n",
       " 'storm',\n",
       " 'fire',\n",
       " 'earthquake',\n",
       " 'cold',\n",
       " 'other_weather',\n",
       " 'direct_report']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "        \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'vect', 'tfidf', 'MOC', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'MOC__estimator__C', 'MOC__estimator__class_weight', 'MOC__estimator__dual', 'MOC__estimator__fit_intercept', 'MOC__estimator__intercept_scaling', 'MOC__estimator__max_iter', 'MOC__estimator__multi_class', 'MOC__estimator__n_jobs', 'MOC__estimator__penalty', 'MOC__estimator__random_state', 'MOC__estimator__solver', 'MOC__estimator__tol', 'MOC__estimator__verbose', 'MOC__estimator__warm_start', 'MOC__estimator', 'MOC__n_jobs'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineRF = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('MOC',MultiOutputClassifier(RandomForestClassifier(n_estimators=10, min_samples_leaf = 1)))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "pipelineSVM = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('MOC',MultiOutputClassifier(svm.SVC()))\n",
    "])\n",
    "\n",
    "pipelineLR = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('MOC',MultiOutputClassifier(LogisticRegression(random_state = 0)))\n",
    "])\n",
    "\n",
    "pipelineLR.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   19906.0\n",
       "request                    4474.0\n",
       "offer                       118.0\n",
       "aid_related               10860.0\n",
       "medical_help               2084.0\n",
       "medical_products           1313.0\n",
       "search_and_rescue           724.0\n",
       "security                    471.0\n",
       "military                    860.0\n",
       "water                      1672.0\n",
       "food                       2923.0\n",
       "shelter                    2314.0\n",
       "clothing                    405.0\n",
       "money                       604.0\n",
       "missing_people              298.0\n",
       "refugees                    875.0\n",
       "death                      1194.0\n",
       "other_aid                  3446.0\n",
       "infrastructure_related     1705.0\n",
       "transport                  1201.0\n",
       "buildings                  1333.0\n",
       "electricity                 532.0\n",
       "tools                       159.0\n",
       "hospitals                   283.0\n",
       "shops                       120.0\n",
       "aid_centers                 309.0\n",
       "other_infrastructure       1151.0\n",
       "weather_related            7297.0\n",
       "floods                     2155.0\n",
       "storm                      2443.0\n",
       "fire                        282.0\n",
       "earthquake                 2455.0\n",
       "cold                        530.0\n",
       "other_weather              1376.0\n",
       "direct_report              5075.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "Y.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14783</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17235</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "4889       1.0      0.0    0.0          0.0           0.0               0.0   \n",
       "14783      1.0      0.0    0.0          0.0           0.0               0.0   \n",
       "13507      1.0      0.0    0.0          1.0           0.0               0.0   \n",
       "10772      1.0      0.0    1.0          1.0           0.0               1.0   \n",
       "17235      1.0      0.0    0.0          0.0           0.0               0.0   \n",
       "\n",
       "       search_and_rescue  security  military  water      ...        \\\n",
       "4889                 0.0       0.0       0.0    0.0      ...         \n",
       "14783                0.0       0.0       0.0    0.0      ...         \n",
       "13507                0.0       0.0       0.0    0.0      ...         \n",
       "10772                0.0       0.0       0.0    0.0      ...         \n",
       "17235                0.0       0.0       0.0    0.0      ...         \n",
       "\n",
       "       aid_centers  other_infrastructure  weather_related  floods  storm  \\\n",
       "4889           0.0                   0.0              0.0     0.0    0.0   \n",
       "14783          0.0                   0.0              0.0     0.0    0.0   \n",
       "13507          0.0                   0.0              1.0     0.0    1.0   \n",
       "10772          0.0                   0.0              0.0     0.0    0.0   \n",
       "17235          0.0                   0.0              0.0     0.0    0.0   \n",
       "\n",
       "       fire  earthquake  cold  other_weather  direct_report  \n",
       "4889    0.0         0.0   0.0            0.0            0.0  \n",
       "14783   0.0         0.0   0.0            0.0            0.0  \n",
       "13507   0.0         0.0   0.0            0.0            0.0  \n",
       "10772   0.0         0.0   0.0            0.0            0.0  \n",
       "17235   0.0         0.0   0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineLR.fit(X_train, y_train)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = pipelineLR.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for column related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.42      0.54      1540\n",
      "        1.0       0.84      0.95      0.89      4967\n",
      "\n",
      "avg / total       0.82      0.83      0.81      6507\n",
      "\n",
      "Values for column request \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95      5396\n",
      "        1.0       0.84      0.59      0.69      1111\n",
      "\n",
      "avg / total       0.91      0.91      0.90      6507\n",
      "\n",
      "Values for column offer \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6477\n",
      "        1.0       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6507\n",
      "\n",
      "Values for column aid_related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.85      0.82      3829\n",
      "        1.0       0.76      0.69      0.72      2678\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6507\n",
      "\n",
      "Values for column medical_help \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96      5985\n",
      "        1.0       0.71      0.18      0.29       522\n",
      "\n",
      "avg / total       0.92      0.93      0.91      6507\n",
      "\n",
      "Values for column medical_products \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6178\n",
      "        1.0       0.81      0.20      0.32       329\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6507\n",
      "\n",
      "Values for column search_and_rescue \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      6328\n",
      "        1.0       0.90      0.05      0.10       179\n",
      "\n",
      "avg / total       0.97      0.97      0.96      6507\n",
      "\n",
      "Values for column security \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6384\n",
      "        1.0       0.00      0.00      0.00       123\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6507\n",
      "\n",
      "Values for column military \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6268\n",
      "        1.0       0.70      0.08      0.14       239\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6507\n",
      "\n",
      "Values for column water \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98      6098\n",
      "        1.0       0.77      0.54      0.63       409\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6507\n",
      "\n",
      "Values for column food \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.98      0.97      5754\n",
      "        1.0       0.83      0.63      0.72       753\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6507\n",
      "\n",
      "Values for column shelter \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97      5972\n",
      "        1.0       0.80      0.47      0.59       535\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Values for column clothing \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6391\n",
      "        1.0       0.79      0.19      0.31       116\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6507\n",
      "\n",
      "Values for column money \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6362\n",
      "        1.0       0.86      0.04      0.08       145\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6507\n",
      "\n",
      "Values for column missing_people \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6432\n",
      "        1.0       0.00      0.00      0.00        75\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Values for column refugees \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6297\n",
      "        1.0       0.44      0.04      0.07       210\n",
      "\n",
      "avg / total       0.95      0.97      0.95      6507\n",
      "\n",
      "Values for column death \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6191\n",
      "        1.0       0.94      0.23      0.37       316\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6507\n",
      "\n",
      "Values for column other_aid \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.99      0.93      5644\n",
      "        1.0       0.60      0.12      0.20       863\n",
      "\n",
      "avg / total       0.84      0.87      0.83      6507\n",
      "\n",
      "Values for column infrastructure_related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97      6077\n",
      "        1.0       0.58      0.03      0.06       430\n",
      "\n",
      "avg / total       0.91      0.93      0.91      6507\n",
      "\n",
      "Values for column transport \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6199\n",
      "        1.0       0.65      0.08      0.15       308\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Values for column buildings \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6174\n",
      "        1.0       0.81      0.23      0.35       333\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6507\n",
      "\n",
      "Values for column electricity \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6392\n",
      "        1.0       0.58      0.06      0.11       115\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6507\n",
      "\n",
      "Values for column tools \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6466\n",
      "        1.0       0.00      0.00      0.00        41\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Values for column hospitals \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6430\n",
      "        1.0       0.00      0.00      0.00        77\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Values for column shops \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6471\n",
      "        1.0       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Values for column aid_centers \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6427\n",
      "        1.0       0.00      0.00      0.00        80\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Values for column other_infrastructure \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6227\n",
      "        1.0       0.55      0.02      0.04       280\n",
      "\n",
      "avg / total       0.94      0.96      0.94      6507\n",
      "\n",
      "Values for column weather_related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.95      0.91      4695\n",
      "        1.0       0.84      0.65      0.73      1812\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6507\n",
      "\n",
      "Values for column floods \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      5961\n",
      "        1.0       0.93      0.38      0.54       546\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Values for column storm \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96      5858\n",
      "        1.0       0.78      0.44      0.56       649\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6507\n",
      "\n",
      "Values for column fire \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6444\n",
      "        1.0       0.67      0.03      0.06        63\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Values for column earthquake \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.99      0.98      5903\n",
      "        1.0       0.90      0.63      0.74       604\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6507\n",
      "\n",
      "Values for column cold \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6373\n",
      "        1.0       0.81      0.10      0.17       134\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6507\n",
      "\n",
      "Values for column other_weather \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6159\n",
      "        1.0       0.65      0.03      0.06       348\n",
      "\n",
      "avg / total       0.93      0.95      0.92      6507\n",
      "\n",
      "Values for column direct_report \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.96      0.92      5245\n",
      "        1.0       0.76      0.50      0.61      1262\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6507\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_df = pd.DataFrame(y_pred, columns = y_test.columns)\n",
    "\n",
    "# y_pred_df['related'].head()\n",
    "# y_test['related'].head()\n",
    "\n",
    "for column in y_test.columns:\n",
    "#     display_results(y_test[column].reset_index(drop=True), y_pred_df[column])\n",
    "    print(\"Values for column\",column,\"\\r\\n\",classification_report(y_test[column].reset_index(drop=True), y_pred_df[column]))\n",
    "\n",
    "\n",
    "# y_test['related'].reset_index(drop=True)\n",
    "# y_pred[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section just looks at all of the different parameters that I have available to choose from to optimize.  I'll optimize the 'MOC__estimator__min_samples_leaf' and 'MOC__estimator__n_estimators' parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x7f65077bb620>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('MOC',\n",
       "   MultiOutputClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False),\n",
       "              n_jobs=1))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x7f65077bb620>, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'MOC': MultiOutputClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       "            n_jobs=1),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'MOC__estimator__C': 1.0,\n",
       " 'MOC__estimator__class_weight': None,\n",
       " 'MOC__estimator__dual': False,\n",
       " 'MOC__estimator__fit_intercept': True,\n",
       " 'MOC__estimator__intercept_scaling': 1,\n",
       " 'MOC__estimator__max_iter': 100,\n",
       " 'MOC__estimator__multi_class': 'ovr',\n",
       " 'MOC__estimator__n_jobs': 1,\n",
       " 'MOC__estimator__penalty': 'l2',\n",
       " 'MOC__estimator__random_state': 0,\n",
       " 'MOC__estimator__solver': 'liblinear',\n",
       " 'MOC__estimator__tol': 0.0001,\n",
       " 'MOC__estimator__verbose': 0,\n",
       " 'MOC__estimator__warm_start': False,\n",
       " 'MOC__estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'MOC__n_jobs': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineLR.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...te=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'MOC__estimator__fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersRF = {\n",
    "    'MOC__estimator__min_samples_leaf': [1,2],\n",
    "    'MOC__estimator__n_estimators':[10, 20]\n",
    "}\n",
    "\n",
    "# cv = GridSearchCV(pipelineRF, param_grid = parameters)\n",
    "# cv.fit(X_train, y_train)\n",
    "\n",
    "parametersLR = {\n",
    "    'MOC__estimator__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipelineLR, param_grid = parametersLR)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MOC__estimator__fit_intercept': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = cv.best_params_\n",
    "# print(best_params['MOC__estimator__min_samples_leaf'] + best_params['MOC__estimator__n_estimators'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MOC__estimator__fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "best_params = {'MOC__estimator__fit_intercept':best_params['MOC__estimator__fit_intercept']}\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...te=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineLR.set_params(**best_params)\n",
    "pipelineLR.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x7f65077bb620>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('MOC',\n",
       "   MultiOutputClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False),\n",
       "              n_jobs=1))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x7f65077bb620>, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'MOC': MultiOutputClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       "            n_jobs=1),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'MOC__estimator__C': 1.0,\n",
       " 'MOC__estimator__class_weight': None,\n",
       " 'MOC__estimator__dual': False,\n",
       " 'MOC__estimator__fit_intercept': True,\n",
       " 'MOC__estimator__intercept_scaling': 1,\n",
       " 'MOC__estimator__max_iter': 100,\n",
       " 'MOC__estimator__multi_class': 'ovr',\n",
       " 'MOC__estimator__n_jobs': 1,\n",
       " 'MOC__estimator__penalty': 'l2',\n",
       " 'MOC__estimator__random_state': 0,\n",
       " 'MOC__estimator__solver': 'liblinear',\n",
       " 'MOC__estimator__tol': 0.0001,\n",
       " 'MOC__estimator__verbose': 0,\n",
       " 'MOC__estimator__warm_start': False,\n",
       " 'MOC__estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'MOC__n_jobs': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineLR.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for column related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.42      0.54      1540\n",
      "        1.0       0.84      0.95      0.89      4967\n",
      "\n",
      "avg / total       0.82      0.83      0.81      6507\n",
      "\n",
      "Values for column request \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95      5396\n",
      "        1.0       0.84      0.59      0.69      1111\n",
      "\n",
      "avg / total       0.91      0.91      0.90      6507\n",
      "\n",
      "Values for column offer \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6477\n",
      "        1.0       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6507\n",
      "\n",
      "Values for column aid_related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.85      0.82      3829\n",
      "        1.0       0.76      0.69      0.72      2678\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6507\n",
      "\n",
      "Values for column medical_help \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96      5985\n",
      "        1.0       0.71      0.18      0.29       522\n",
      "\n",
      "avg / total       0.92      0.93      0.91      6507\n",
      "\n",
      "Values for column medical_products \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6178\n",
      "        1.0       0.81      0.20      0.32       329\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6507\n",
      "\n",
      "Values for column search_and_rescue \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      6328\n",
      "        1.0       0.90      0.05      0.10       179\n",
      "\n",
      "avg / total       0.97      0.97      0.96      6507\n",
      "\n",
      "Values for column security \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6384\n",
      "        1.0       0.00      0.00      0.00       123\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6507\n",
      "\n",
      "Values for column military \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6268\n",
      "        1.0       0.70      0.08      0.14       239\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6507\n",
      "\n",
      "Values for column water \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98      6098\n",
      "        1.0       0.77      0.54      0.63       409\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6507\n",
      "\n",
      "Values for column food \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.98      0.97      5754\n",
      "        1.0       0.83      0.63      0.72       753\n",
      "\n",
      "avg / total       0.94      0.94      0.94      6507\n",
      "\n",
      "Values for column shelter \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97      5972\n",
      "        1.0       0.80      0.47      0.59       535\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Values for column clothing \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6391\n",
      "        1.0       0.79      0.19      0.31       116\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6507\n",
      "\n",
      "Values for column money \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6362\n",
      "        1.0       0.86      0.04      0.08       145\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6507\n",
      "\n",
      "Values for column missing_people \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6432\n",
      "        1.0       0.00      0.00      0.00        75\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Values for column refugees \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6297\n",
      "        1.0       0.44      0.04      0.07       210\n",
      "\n",
      "avg / total       0.95      0.97      0.95      6507\n",
      "\n",
      "Values for column death \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6191\n",
      "        1.0       0.94      0.23      0.37       316\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6507\n",
      "\n",
      "Values for column other_aid \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.99      0.93      5644\n",
      "        1.0       0.60      0.12      0.20       863\n",
      "\n",
      "avg / total       0.84      0.87      0.83      6507\n",
      "\n",
      "Values for column infrastructure_related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97      6077\n",
      "        1.0       0.58      0.03      0.06       430\n",
      "\n",
      "avg / total       0.91      0.93      0.91      6507\n",
      "\n",
      "Values for column transport \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6199\n",
      "        1.0       0.65      0.08      0.15       308\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Values for column buildings \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6174\n",
      "        1.0       0.81      0.23      0.35       333\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6507\n",
      "\n",
      "Values for column electricity \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6392\n",
      "        1.0       0.58      0.06      0.11       115\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6507\n",
      "\n",
      "Values for column tools \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6466\n",
      "        1.0       0.00      0.00      0.00        41\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Values for column hospitals \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6430\n",
      "        1.0       0.00      0.00      0.00        77\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Values for column shops \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6471\n",
      "        1.0       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Values for column aid_centers \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6427\n",
      "        1.0       0.00      0.00      0.00        80\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Values for column other_infrastructure \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6227\n",
      "        1.0       0.55      0.02      0.04       280\n",
      "\n",
      "avg / total       0.94      0.96      0.94      6507\n",
      "\n",
      "Values for column weather_related \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.95      0.91      4695\n",
      "        1.0       0.84      0.65      0.73      1812\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6507\n",
      "\n",
      "Values for column floods \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      5961\n",
      "        1.0       0.93      0.38      0.54       546\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Values for column storm \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96      5858\n",
      "        1.0       0.78      0.44      0.56       649\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6507\n",
      "\n",
      "Values for column fire \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6444\n",
      "        1.0       0.67      0.03      0.06        63\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Values for column earthquake \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.99      0.98      5903\n",
      "        1.0       0.90      0.63      0.74       604\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6507\n",
      "\n",
      "Values for column cold \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6373\n",
      "        1.0       0.81      0.10      0.17       134\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6507\n",
      "\n",
      "Values for column other_weather \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6159\n",
      "        1.0       0.65      0.03      0.06       348\n",
      "\n",
      "avg / total       0.93      0.95      0.92      6507\n",
      "\n",
      "Values for column direct_report \r\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.96      0.92      5245\n",
      "        1.0       0.76      0.50      0.61      1262\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6507\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = pipelineLR.predict(X_test)\n",
    "y_pred_df2 = pd.DataFrame(y_pred2, columns = y_test.columns)\n",
    "\n",
    "# y_pred_df['related'].head()\n",
    "# y_test['related'].head()\n",
    "\n",
    "for column in y_test.columns:\n",
    "#     display_results(y_test[column].reset_index(drop=True), y_pred_df[column])\n",
    "    print(\"Values for column\",column,\"\\r\\n\",classification_report(y_test[column].reset_index(drop=True), y_pred_df2[column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('MOC',MultiOutputClassifier(RandomForestClassifier(n_estimators=20, min_samples_leaf = 1)))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline2.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# y_pred_df = pd.DataFrame(y_pred, columns = y_test.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pipeline2RFC.sav'\n",
    "pickle.dump(pipeline2, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_dump']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline2, 'model_dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model = pickle.load(open(filename, 'rb'))\n",
    "pickled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_upload = joblib.load('model_dump')\n",
    "joblib_upload.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
